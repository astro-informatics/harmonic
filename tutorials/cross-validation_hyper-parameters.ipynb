{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/astro-informatics/harmonic/blob/main/notebooks/cross_validation_hyper_parameters.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyper-parameter cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial we demonstrate basic usage of harmonic, using [emcee](https://emcee.readthedocs.io/en/stable/) as the sampler.\n",
    "\n",
    "The tutorial is very similar to the basic usage tutorial but here we use harmonic's cross-validation functionality to select the hyper-parameters of the machine learning model used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages\n",
    "\n",
    "To begin with we need to import packages needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import emcee\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import partial\n",
    "import sys\n",
    "sys.path.insert(0, '../../..')\n",
    "import harmonic as hm\n",
    "sys.path.append(\"../../../examples\")\n",
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Bayesian posterior function\n",
    "\n",
    "Now we will need to define the log-posterior function of interest. \n",
    "\n",
    "As a working example for this tutorial we consider a likelihood given by the [Rosenbrock function](https://en.wikipedia.org/wiki/Rosenbrock_function)\n",
    "\n",
    "$$\n",
    "f(x) = \\sum_{i=1}^{d-1} \\bigg [ b(x_{i+1} - x_{i}^2)^2 + (x_i - a)^2 \\bigg ]\n",
    "$$\n",
    "\n",
    "where $d$ is the dimension of the function and the input domain is usually taken to be $x_i \\in [-5.0, 10.0], \\: \\; \\forall i = 1, \\dots, d$.  The Rosenbrock function is a common benchmark example since it is known to be a difficult project due to the shallow curving degenercy.  The likelihood is then implemented as follows.  For the hyper-parameters we adopt the common values $a=1.0$ and $b=100.0$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ln_likelihood(x, a=1.0, b=100.0):\n",
    "    \"\"\"Compute log_e of likelihood defined by Rosenbrock function.\n",
    "    \n",
    "    Args: \n",
    "    \n",
    "        x: Position at which to evaluate likelihood.\n",
    "        \n",
    "        a: First parameter of Rosenbrock function. \n",
    "        \n",
    "        b: First parameter of Rosenbrock function. \n",
    "        \n",
    "    Returns:\n",
    "    \n",
    "        double: Value of Rosenbrock at specified point.\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    ndim = x.size\n",
    "\n",
    "    f = 0.0\n",
    "\n",
    "    for i_dim in range(ndim-1):\n",
    "        f += b*(x[i_dim+1]-x[i_dim]**2)**2 + (a-x[i_dim])**2\n",
    "\n",
    "    return -f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We adopt a uniform prior over the parameter support $x_i \\in [-5.0, 10.0]$, which is implemented as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ln_prior_uniform(x, xmin=-10.0, xmax=10.0, ymin=-5.0, ymax=15.0):\n",
    "    \"\"\"Compute log_e of uniform prior.\n",
    "    \n",
    "    Args: \n",
    "    \n",
    "        x: Position at which to evaluate prior.\n",
    "        \n",
    "        xmin: Uniform prior minimum x edge (first dimension).\n",
    "        \n",
    "        xmax: Uniform prior maximum x edge (first dimension).\n",
    "        \n",
    "        ymin: Uniform prior minimum y edge (second dimension).\n",
    "        \n",
    "        ymax: Uniform prior maximum y edge (second dimension).\n",
    "        \n",
    "    Returns:\n",
    "    \n",
    "        double: Value of prior at specified point.\n",
    "        \n",
    "    \"\"\"\n",
    "        \n",
    "    if x[0] >= xmin and x[0] <= xmax and x[1] >= ymin and x[1] <= ymax:        \n",
    "        return 1.0 / ( (xmax - xmin) * (ymax - ymin) )\n",
    "    else:\n",
    "        return 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The likelihood and prior are combined to form the log posterior function as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ln_posterior(x, ln_prior, a=1.0, b=100.0):\n",
    "    \"\"\"Compute log_e of posterior.\n",
    "    \n",
    "    Args: \n",
    "    \n",
    "        x: Position at which to evaluate posterior.\n",
    "        \n",
    "        a: First parameter of Rosenbrock function.\n",
    "        \n",
    "        b: First parameter of Rosenbrock function.\n",
    "        \n",
    "        ln_prior: Prior function.\n",
    "        \n",
    "    Returns:\n",
    "    \n",
    "        double: Posterior at specified point.\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    ln_L = ln_likelihood(x, a=a, b=b)\n",
    "\n",
    "    if not np.isfinite(ln_L):\n",
    "        return -np.inf\n",
    "    else:\n",
    "        return ln_prior(x) + ln_L"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute samples using emcee\n",
    "\n",
    "We then sample from the posterior using an MCMC algorithm. While any MCMC approach can be used we sample using the [emcee](https://emcee.readthedocs.io/en/stable/) package.\n",
    "\n",
    "First we will need to define and initialise some variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameters for emcee sampling\n",
    "ndim = 2                    # number of dimensions\n",
    "nchains = 200               # total number of chains to compute\n",
    "samples_per_chain = 5000    # number of samples per chain\n",
    "nburn = 2000                # number of samples to discard as burn in\n",
    "\n",
    "# initialise random seed\n",
    "np.random.seed(2)\n",
    "\n",
    "# Rosenbrock hyper-parameters\n",
    "a = 1.0\n",
    "b = 100.0\n",
    "\n",
    "# Define ln_prior function\n",
    "xmin = -10.0\n",
    "xmax = 10.0\n",
    "ymin = -5.0\n",
    "ymax = 15.0  \n",
    "ln_prior = partial(ln_prior_uniform, xmin=xmin, xmax=xmax, ymin=ymin, ymax=ymax)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to run the sampler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set initial random position and state\n",
    "pos = np.random.rand(ndim * nchains).reshape((nchains, ndim)) * 0.1   \n",
    "rstate = np.random.get_state()\n",
    "\n",
    "# Instantiate and execute sampler \n",
    "sampler = emcee.EnsembleSampler(nchains, ndim, ln_posterior, args=[ln_prior, a, b])\n",
    "(pos, prob, state) = sampler.run_mcmc(pos, samples_per_chain, rstate0=rstate) \n",
    "\n",
    "# Collect samples into contiguous numpy arrays (discarding burn in)\n",
    "samples = np.ascontiguousarray(sampler.chain[:,nburn:,:])\n",
    "lnprob = np.ascontiguousarray(sampler.lnprobability[:,nburn:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute evidence using harmonic\n",
    "\n",
    "The harmonic package requires only posterior samples.  There are no constraints on the type of sampling algorithm used.\n",
    "\n",
    "Once we have posterior samples to hand, they can be post-processed using harmonic to compute the Bayesian evidence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collating samples using harmonic.chains class\n",
    "\n",
    "We first configure the chains into a harmonic-friendly shape, which we do as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate harmonic's chains class \n",
    "chains = hm.Chains(ndim)\n",
    "chains.add_chains_3d(samples, lnprob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we will subsequently learn the target distribution $\\varphi$ we split the samples into training and inference sets (we often use the common machine learning terminology \"test\" for the inference data-set)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the chains into the ones which will be used to train the machine \n",
    "# learning model and for inference\n",
    "chains_train, chains_infer = hm.utils.split_data(chains, training_proportion=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the machine learning model\n",
    "\n",
    "Now consider `chains_train` and use the chains to train the model. Here we will use the Kernel Density Estimation model. \n",
    "\n",
    "We will perform cross-validation to select appropriate model hyper-parameters.  First we define the cross-validation set-up, including a set of hyper-parameters to consider."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model hyper-parameters and domain\n",
    "nfold = 2\n",
    "nhyper = 2\n",
    "step = -2\n",
    "domain = [] # not used for KDE model\n",
    "hyper_parameters = [[10**(R)] for R in range(-nhyper+step,step)] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross-validation is then performing using harmonic utils to select the best hyper-parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_variances = \\\n",
    "            hm.utils.cross_validation(\n",
    "                    chains_train, \\\n",
    "                    domain, \\\n",
    "                    hyper_parameters, \\\n",
    "                    nfold=nfold, \\\n",
    "                    modelClass=hm.model.KernelDensityEstimate, \\\n",
    "                    seed=0)\n",
    "\n",
    "best_hyper_param_ind = np.argmin(validation_variances)\n",
    "best_hyper_param = hyper_parameters[best_hyper_param_ind]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we simply instantiate the model and train it using the selected hyper-parameters and the training chains generated previously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = hm.model.KernelDensityEstimate(ndim, \n",
    "                                       domain, \n",
    "                                       hyper_parameters=best_hyper_param)\n",
    "fit_success = model.fit(chains_train.samples, chains_train.ln_posterior)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute the Bayesian evidence\n",
    "\n",
    "Finally we simply compute the learnt harmonic mean estimator as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate harmonic's evidence class\n",
    "ev = hm.Evidence(chains_infer.nchains, model)\n",
    "\n",
    "# Pass the evidence class the inference chains and compute the evidence!\n",
    "ev.add_chains(chains_infer)\n",
    "evidence, evidence_std = ev.compute_evidence()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "Let's check the evidence value computed and also plot the posterior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numerical integration\n",
    "\n",
    "For this 2D model, we can compute the evidence by brute force numerical integration to compare to the value computed by harmonic. (Of course, numerical integration is not typically possible for higher dimensional models.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ln_posterior_func = partial(ln_posterior, ln_prior=ln_prior, a=a, b=b)\n",
    "ln_posterior_grid, x_grid, y_grid = utils.eval_func_on_grid(\n",
    "                                        ln_posterior_func, \n",
    "                                        xmin=xmin, xmax=xmax, \n",
    "                                        ymin=ymin, ymax=ymax, \n",
    "                                        nx=1000, ny=1000)\n",
    "dx = x_grid[0,1] - x_grid[0,0]\n",
    "dy = y_grid[1,0] - y_grid[0,0]\n",
    "evidence_numerical = np.sum(np.exp(ln_posterior_grid))*dx*dy\n",
    "ln_evidence_numerical = np.log(evidence_numerical)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compare the value computed by harmonic and by numerical integration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evidence (harmonic) = 0.31445923801957426 +/- 0.006538434524987667\n",
      "evidence (numerical integration) = 0.31493806556881776\n",
      "nsigma = 0.07323275126692534\n"
     ]
    }
   ],
   "source": [
    "print('evidence (harmonic) = {} +/- {}'.format(evidence, evidence_std))\n",
    "print('evidence (numerical integration) = {}'.format(evidence_numerical))\n",
    "print('nsigma = {}'.format(np.abs(evidence - evidence_numerical) / evidence_std))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, the evidence computed by harmonic is close to that computed by numerical integration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Posterior triangle plot\n",
    "\n",
    "Out of interest let's also plot slices of the posterior using these samples to see what we're working with!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 288x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "utils.plot_getdist(samples.reshape((-1, ndim)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
