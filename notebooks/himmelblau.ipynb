{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import emcee\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import partial\n",
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "import harmonic as hm\n",
    "sys.path.append(\"../examples\")\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ln_prior_uniform(x, xmin=-6.0, xmax=6.0, ymin=-6.0, ymax=6.0):\n",
    "    if x[0] >= xmin and x[0] <= xmax and x[1] >= ymin and x[1] <= ymax:        \n",
    "        return 1.0 / ( (xmax - xmin) * (ymax - ymin) )\n",
    "    else:\n",
    "        return 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def ln_likelihood(x):\n",
    "#     f = (x[0]**2 + x[1] - 11.0)**2 + (x[0] + x[1]**2 - 7.0)**2\n",
    "#     return -f\n",
    "def ln_likelihood(x):\n",
    "    \"\"\"Compute log_e of likelihood defined by Rastrigin function.\n",
    "\n",
    "    Args:\n",
    "\n",
    "        x: Position at which to evaluate likelihood.\n",
    "\n",
    "    Returns:\n",
    "\n",
    "        double: Value of Rastrigin at specified point.\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    ndim = x.size\n",
    "\n",
    "    f = 10.0 * ndim\n",
    "\n",
    "    for i_dim in range(ndim):\n",
    "        f += x[i_dim]**2 - 10.0 * np.cos( 2.0 * np.pi * x[i_dim] )\n",
    "\n",
    "    return -f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ln_posterior(x, ln_prior):\n",
    "    ln_L = ln_likelihood(x)\n",
    "\n",
    "    if not np.isfinite(ln_L):\n",
    "        return -np.inf\n",
    "    else:\n",
    "        return ln_prior(x) + ln_L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameters for emcee sampling\n",
    "ndim = 2                    # number of dimensions\n",
    "nchains = 200               # total number of chains to compute\n",
    "samples_per_chain = 5000    # number of samples per chain\n",
    "nburn = 2000                # number of samples to discard as burn in\n",
    "\n",
    "# Initialize random seed\n",
    "np.random.seed(4)\n",
    "\n",
    "# Define ln_prior function\n",
    "xmin = -6.0\n",
    "xmax = 6.0\n",
    "ymin = -6.0\n",
    "ymax = 6.0  \n",
    "ln_prior = partial(ln_prior_uniform, xmin=xmin, xmax=xmax, ymin=ymin, ymax=ymax)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set initial random position and state\n",
    "pos = np.random.rand(ndim * nchains).reshape((nchains, ndim)) * 0.5  \n",
    "rstate = np.random.get_state()\n",
    "\n",
    "# Instantiate and execute sampler \n",
    "sampler = emcee.EnsembleSampler(nchains, ndim, ln_posterior, args=[ln_prior])\n",
    "(pos, prob, state) = sampler.run_mcmc(pos, samples_per_chain, rstate0=rstate) \n",
    "\n",
    "# Collect samples into contiguous numpy arrays (discarding burn in)\n",
    "samples = np.ascontiguousarray(sampler.chain[:,nburn:,:])\n",
    "lnprob = np.ascontiguousarray(sampler.lnprobability[:,nburn:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate harmonic's chains class \n",
    "chains = hm.Chains(ndim)\n",
    "chains.add_chains_3d(samples, lnprob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the chains into the ones which will be used to train the machine \n",
    "# learning model and for inference\n",
    "chains_train, chains_infer = hm.utils.split_data(chains, training_proportion=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Kernel Density Estimate (KDE) hyperparameters\n",
    "nfold = 2\n",
    "nhyper = 2\n",
    "step = -2\n",
    "domains_KDE = [] # no defined domain for KDE estimate\n",
    "hyper_parameters_KDE = [[10**(R)] for R in range(-nhyper+step,step)] \n",
    "\n",
    "# Define Hypersphere (sphere) hyperparameters\n",
    "hyper_parameters_sphere = [None]\n",
    "domains_sphere = [np.array([1E-2,1E1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_variances_KDE = \\\n",
    "            hm.utils.cross_validation(\n",
    "                    chains_train, \\\n",
    "                    domains_KDE, \\\n",
    "                    hyper_parameters_KDE, \\\n",
    "                    nfold=nfold, \\\n",
    "                    modelClass=hm.model.KernelDensityEstimate, \\\n",
    "                    seed=0)\n",
    "best_hyper_param_ind_KDE = np.argmin(validation_variances_KDE)\n",
    "best_hyper_param_KDE = hyper_parameters_KDE[best_hyper_param_ind_KDE]\n",
    "best_var_KDE = validation_variances_KDE[best_hyper_param_ind_KDE]\n",
    "\n",
    "validation_variances_sphere = \\\n",
    "            hm.utils.cross_validation(\n",
    "                    chains_train, \\\n",
    "                    domains_sphere, \\\n",
    "                    hyper_parameters_sphere, \\\n",
    "                    nfold=nfold, \\\n",
    "                    modelClass=hm.model.HyperSphere, \\\n",
    "                    seed=0)\n",
    "\n",
    "best_hyper_param_ind_sphere = np.argmin(validation_variances_sphere)\n",
    "best_hyper_param_sphere = hyper_parameters_sphere[best_hyper_param_ind_sphere]\n",
    "best_var_sphere = validation_variances_sphere[best_hyper_param_ind_sphere]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_var_sphere = -8.616605704089338\n",
      "best_var_KDE = -3.595846079140736\n",
      "Using Hypersphere model!\n"
     ]
    }
   ],
   "source": [
    "print(\"best_var_sphere = {}\".format(best_var_sphere))\n",
    "print(\"best_var_KDE = {}\".format(best_var_KDE))\n",
    "\n",
    "if best_var_sphere < best_var_KDE:                        \n",
    "        model = hm.model.HyperSphere(ndim, domains_sphere, \n",
    "                                     hyper_parameters=best_hyper_param_sphere)\n",
    "        print('Using Hypersphere model!')\n",
    "  \n",
    "else:                       \n",
    "        model = hm.model.KernelDensityEstimate(ndim, domains_KDE, \n",
    "                                               hyper_parameters=best_hyper_param_KDE)\n",
    "        print('Using Kernel Density Estimate model!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f8d048cbc53068e207ac0bbd1e2d7faac53648ed19cf54011f4834f48a516020"
  },
  "kernelspec": {
   "display_name": "Python 3.6.2 64-bit ('harmonic': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
