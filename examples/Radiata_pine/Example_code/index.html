<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>&lt;no title&gt; &mdash; Harmonic 1.0.1 documentation</title>
      <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="../../../_static/css/custom.css" type="text/css" />
      <link rel="stylesheet" href="../../../_static/css/custom_tabs.css" type="text/css" />
      <link rel="stylesheet" href="../../../_static/dark_mode_css/general.css" type="text/css" />
      <link rel="stylesheet" href="../../../_static/dark_mode_css/dark.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
        <script src="../../../_static/jquery.js"></script>
        <script src="../../../_static/underscore.js"></script>
        <script src="../../../_static/doctools.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
        <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
        <script>window.MathJax = {"tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true}, "options": {"ignoreHtmlClass": "tex2jax_ignore|mathjax_ignore|document", "processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
        <script src="../../../_static/dark_mode_js/default_light.js"></script>
        <script src="../../../_static/dark_mode_js/theme_switcher.js"></script>
    <script src="../../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../../../index.html">
            <img src="../../../_static/harm_badge_simple.svg" class="logo" alt="Logo"/>
          </a>
              <div class="version">
                1.0.1
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">User Guide</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../user_guide/install.html">Installation</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Mathematics</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../background/Harmonic_Estimator/index.html">Harmonic Mean Estimator</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../background/Machine_Learning/index.html">Learnt Container Function</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Tutorials</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../tutorials/index.html">Jupyter Notebooks</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Examples</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../index.html">Benchmark Examples</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../api/index.html">Namespaces</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Changelog</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../api/changes.html">GitHub History</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../index.html">Harmonic</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../index.html" class="icon icon-home"></a> &raquo;</li>
      <li>&lt;no title&gt;</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../../_sources/examples/Radiata_pine/Example_code/index.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  
<style>
/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<p>We consider another example where the original harmonic mean estimator was shown to fail catastrophically. In particular, we consider non-nested linear regression models for the <strong>Radiata pine</strong> data, which is another common benchmark data-set, and show that our learnt harmonic mean estimator is highly accurate.</p>
<p>For <span class="math notranslate nohighlight">\(n=42\)</span> trees, the Radiata pine data-set includes measurements of the maximum compression strength parallel to the grain <span class="math notranslate nohighlight">\(y_i\)</span>, density <span class="math notranslate nohighlight">\(x_i\)</span> and resin-adjusted density <span class="math notranslate nohighlight">\(z_i\)</span>, for specimen <span class="math notranslate nohighlight">\(i \in \{1, \ldots, n\}\)</span>.  The question at hand is whether density or resin-adjusted density is a better predictor of compression strength. This motivates two Gaussian linear regression models:</p>
<div class="math notranslate nohighlight">
\begin{align}
&amp;M_1 : y_i = \alpha + \beta(x_i - \bar{x}) + \epsilon_i, \epsilon_i \sim \text{N}(0, \tau^{-1}), \\
&amp;M_2 : y_i = \gamma + \delta(z_i - \bar{z}) + \eta_i, \eta_i \sim \text{N}(0, \lambda^{-1}),
\end{align}</div><p>where <span class="math notranslate nohighlight">\(\bar{x} = \frac{1}{n} \sum_{i=1}^n x_i\)</span>, <span class="math notranslate nohighlight">\(\bar{z} = \frac{1}{n} \sum_{i=1}^n z_i\)</span>, and <span class="math notranslate nohighlight">\(\tau\)</span> and <span class="math notranslate nohighlight">\(\lambda\)</span> denote the precision (inverse variance) of the noise for the respective models.</p>
<p>For Model 1, Gaussian priors are assumed for the bias and linear terms:</p>
<div class="math notranslate nohighlight">
       \begin{align}
       &amp;\alpha \sim \text{N}\bigl(\mu_\alpha, (r_0 \tau)^{-1}\bigr), \\
       &amp;\beta  \sim \text{N}\bigl(\mu_\beta, (s_0 \tau)^{-1}\bigr),
       \end{align}</div><p>with means <span class="math notranslate nohighlight">\(\mu_\alpha = 3000\)</span> and <span class="math notranslate nohighlight">\(\mu_\beta = 185\)</span>, and precision scales <span class="math notranslate nohighlight">\(r_0 = 0.06\)</span> and <span class="math notranslate nohighlight">\(s_0 = 6\)</span>.  A gamma prior <span class="math notranslate nohighlight">\(\tau \sim \text{Ga}(a_0, b_0)\)</span> is assumed for the noise precision with shape <span class="math notranslate nohighlight">\(a_0 = 3\)</span> and rate <span class="math notranslate nohighlight">\(b_0 = 2 \times 300^2\)</span>. The joint prior for <span class="math notranslate nohighlight">\((\alpha, \beta, \tau)\)</span> then reads:</p>
<div class="math notranslate nohighlight">
        \begin{align}
        \pi(\alpha, \beta, \tau) &amp;= \pi(\alpha, \beta | \tau) \pi(\tau) = \pi(\alpha | \tau) \pi(\beta | \tau) \pi(\tau) \\
                         &amp;= \frac{(b_0\tau_0)^{a_0} (r_0 s_0)^{1/2} }{2 \pi \Gamma(a_0)} \exp\bigl(-b_0 \tau\bigr) \exp\biggl(-\frac{\tau}{2}\Bigl(r_0(\alpha-\mu_\alpha)^2 + s_0(\beta-\mu_\beta)^2\Bigr)\biggr).
\end{align}</div><p>The likelihood for Model 1 is given by</p>
<div class="math notranslate nohighlight">
        \begin{align}
        \mathcal{L}({x}, {y}) &amp;= \prod_{i=1}^n \text{P}(x_i, y_i | \alpha, \beta, \tau), \\
                      &amp;= \prod_{i=1}^n \sqrt{\frac{\tau}{2\pi}} \exp\Bigl(- \frac{\tau}{2} \bigl(y_i - \alpha - \beta (x_i - \bar{x})\bigr)^2\Bigr), \\
                      &amp;= \Bigl(\frac{\tau}{2\pi}\Bigr)^{n/2} \exp\biggl(- \frac{\tau}{2} \sum_{i=1}^n \bigl(y_i - \alpha - \beta (x_i - \bar{x})\bigr)^2\biggr),
\end{align}</div><p>where <span class="math notranslate nohighlight">\(x = (x_1, \dots, x_n)^\text{T}\)</span> and <span class="math notranslate nohighlight">\(y = (y_1, \dots, y_n)^\text{T}\)</span>.  For Model 2, the priors adopted for <span class="math notranslate nohighlight">\((\gamma, \delta, \lambda)\)</span> are the same as those adopted for <span class="math notranslate nohighlight">\((\alpha, \beta, \tau)\)</span> of Model 1, respectively, with the same hyper-parameters.  The likelihood for Model 2 again takes an identical form to Model 1, and is presented in the DAG below.</p>
<a class="reference internal image-reference" href="../../../_images/hbm_radiata_pine.svg"><img alt="../../../_images/hbm_radiata_pine.svg" class="align-center" src="../../../_images/hbm_radiata_pine.svg" width="50%" /></a>
<p>The log-likelihood function is given by</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">ln_likelihood</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">beta</span><span class="p">,</span> <span class="n">tau</span><span class="p">):</span>

 <span class="n">ln_like</span> <span class="o">=</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">n</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">tau</span><span class="p">)</span>
 <span class="n">ln_like</span> <span class="o">-=</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">n</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mf">2.0</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="p">)</span>
 <span class="n">s</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="n">y</span> <span class="o">-</span> <span class="n">alpha</span> <span class="o">-</span> <span class="n">beta</span> <span class="o">*</span> <span class="n">x</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
 <span class="n">ln_like</span> <span class="o">-=</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">tau</span> <span class="o">*</span> <span class="n">s</span>

 <span class="k">return</span> <span class="n">ln_like</span>
</pre></div>
</div>
<p>The combined log-prior is given by</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">ln_prior</span><span class="p">(</span><span class="n">alpha</span><span class="p">,</span> <span class="n">beta</span><span class="p">,</span> <span class="n">tau</span><span class="p">,</span> <span class="n">mu_0</span><span class="p">,</span> <span class="n">r_0</span><span class="p">,</span> <span class="n">s_0</span><span class="p">,</span> <span class="n">a_0</span><span class="p">,</span> <span class="n">b_0</span><span class="p">):</span>

 <span class="k">if</span> <span class="n">tau</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
     <span class="k">return</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span>

 <span class="n">ln_pr</span> <span class="o">=</span> <span class="n">a_0</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">b_0</span><span class="p">)</span>
 <span class="n">ln_pr</span> <span class="o">+=</span> <span class="n">a_0</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">tau</span><span class="p">)</span>
 <span class="n">ln_pr</span> <span class="o">-=</span> <span class="n">b_0</span> <span class="o">*</span> <span class="n">tau</span>
 <span class="n">ln_pr</span> <span class="o">-=</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mf">2.0</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="p">)</span>
 <span class="n">ln_pr</span> <span class="o">-=</span> <span class="n">sp</span><span class="o">.</span><span class="n">gammaln</span><span class="p">(</span><span class="n">a_0</span><span class="p">)</span>
 <span class="n">ln_pr</span> <span class="o">+=</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">r_0</span><span class="p">)</span>
 <span class="n">ln_pr</span> <span class="o">+=</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">s_0</span><span class="p">)</span>
 <span class="n">ln_pr</span> <span class="o">-=</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">tau</span> <span class="o">*</span> <span class="p">(</span><span class="n">r_0</span> <span class="o">*</span> <span class="p">(</span><span class="n">alpha</span> <span class="o">-</span> <span class="n">mu_0</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">])</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="n">s_0</span> <span class="o">*</span> <span class="p">(</span><span class="n">beta</span> <span class="o">-</span> <span class="n">mu_0</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">])</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>

 <span class="k">return</span> <span class="n">ln_pr</span>
</pre></div>
</div>
<p>We may then combine the log-likelihood and log-prior functions to define the log-posterior function simply by</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">ln_posterior</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">mu_0</span><span class="p">,</span> <span class="n">r_0</span><span class="p">,</span> <span class="n">s_0</span><span class="p">,</span> <span class="n">a_0</span><span class="p">,</span> <span class="n">b_0</span><span class="p">):</span>

 <span class="n">alpha</span><span class="p">,</span> <span class="n">beta</span><span class="p">,</span> <span class="n">tau</span> <span class="o">=</span> <span class="n">theta</span>
 <span class="n">ln_pr</span> <span class="o">=</span> <span class="n">ln_prior</span><span class="p">(</span><span class="n">alpha</span><span class="p">,</span> <span class="n">beta</span><span class="p">,</span> <span class="n">tau</span><span class="p">,</span> <span class="n">mu_0</span><span class="p">,</span> <span class="n">r_0</span><span class="p">,</span> <span class="n">s_0</span><span class="p">,</span> <span class="n">a_0</span><span class="p">,</span> <span class="n">b_0</span><span class="p">)</span>

 <span class="k">if</span> <span class="ow">not</span> <span class="n">np</span><span class="o">.</span><span class="n">isfinite</span><span class="p">(</span><span class="n">ln_pr</span><span class="p">):</span>
     <span class="k">return</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span>

 <span class="n">ln_L</span> <span class="o">=</span> <span class="n">ln_likelihood</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">beta</span><span class="p">,</span> <span class="n">tau</span><span class="p">)</span>

 <span class="k">return</span>  <span class="n">ln_L</span> <span class="o">+</span> <span class="n">ln_pr</span>
</pre></div>
</div>
<p>Further as discussed we can explicitly calculate the analytic evidence by defining a function such as</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">ln_evidence_analytic</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">mu_0</span><span class="p">,</span> <span class="n">r_0</span><span class="p">,</span> <span class="n">s_0</span><span class="p">,</span> <span class="n">a_0</span><span class="p">,</span> <span class="n">b_0</span><span class="p">):</span>

 <span class="n">Q_0</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">diag</span><span class="p">([</span><span class="n">r_0</span><span class="p">,</span> <span class="n">s_0</span><span class="p">])</span>
 <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">c_</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">n</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span> <span class="n">x</span><span class="p">]</span>
 <span class="n">M</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">X</span><span class="p">)</span> <span class="o">+</span> <span class="n">Q_0</span>
 <span class="n">nu_0</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">inv</span><span class="p">(</span><span class="n">M</span><span class="p">)</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">y</span><span class="p">)</span> <span class="o">+</span> <span class="n">Q_0</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">mu_0</span><span class="p">))</span>

 <span class="n">quad_terms</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">y</span><span class="p">)</span> <span class="o">+</span> <span class="n">mu_0</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">Q_0</span><span class="p">)</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">mu_0</span><span class="p">)</span> <span class="o">-</span> <span class="n">nu_0</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">M</span><span class="p">)</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">nu_0</span><span class="p">)</span>

 <span class="n">ln_evidence</span> <span class="o">=</span> <span class="o">-</span><span class="mf">0.5</span> <span class="o">*</span> <span class="n">n</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="p">)</span>
 <span class="n">ln_evidence</span> <span class="o">+=</span> <span class="n">a_0</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mf">2.0</span><span class="o">*</span><span class="n">b_0</span><span class="p">)</span>
 <span class="n">ln_evidence</span> <span class="o">+=</span> <span class="n">sp</span><span class="o">.</span><span class="n">gammaln</span><span class="p">(</span><span class="mf">0.5</span><span class="o">*</span><span class="n">n</span> <span class="o">+</span> <span class="n">a_0</span><span class="p">)</span> <span class="o">-</span> <span class="n">sp</span><span class="o">.</span><span class="n">gammaln</span><span class="p">(</span><span class="n">a_0</span><span class="p">)</span>
 <span class="n">ln_evidence</span> <span class="o">+=</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">det</span><span class="p">(</span><span class="n">Q_0</span><span class="p">))</span> <span class="o">-</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">det</span><span class="p">(</span><span class="n">M</span><span class="p">))</span>
 <span class="n">ln_evidence</span> <span class="o">+=</span> <span class="o">-</span><span class="p">(</span><span class="mf">0.5</span> <span class="o">*</span> <span class="n">n</span> <span class="o">+</span> <span class="n">a_0</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">quad_terms</span> <span class="o">+</span> <span class="mf">2.0</span> <span class="o">*</span> <span class="n">b_0</span><span class="p">)</span>

 <span class="k">return</span> <span class="n">ln_evidence</span>
</pre></div>
</div>
<p>The first step of our evidence computation requires recovering a relatively small number of samples from the given posterior. This can be done in whatever way the user wishes, the only requirement being that a set of chains each with associated samples is provided for subsequent steps.
In our examples we choose to use the excellent <a class="reference external" href="http://dfm.io/emcee/current/">emcee</a> python package. Utilizing emcee this example recovers samples via</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">pos_alpha</span> <span class="o">=</span> <span class="n">mu_0</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="mf">1.0</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">tau_prior_mean</span> <span class="o">*</span> <span class="n">r_0</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">nchains</span><span class="p">)</span>
<span class="n">pos_beta</span> <span class="o">=</span> <span class="n">mu_0</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="mf">1.0</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">tau_prior_mean</span> <span class="o">*</span> <span class="n">s_0</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">nchains</span><span class="p">)</span>
<span class="n">pos_tau</span> <span class="o">=</span> <span class="n">tau_prior_mean</span> <span class="o">+</span> <span class="n">tau_prior_std</span> <span class="o">*</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">nchains</span><span class="p">)</span> <span class="o">-</span> <span class="mf">0.5</span><span class="p">)</span>
<span class="n">pos</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">c_</span><span class="p">[</span><span class="n">pos_alpha</span><span class="p">,</span> <span class="n">pos_beta</span><span class="p">,</span> <span class="n">pos_tau</span><span class="p">]</span>

<span class="k">if</span> <span class="n">model_1</span><span class="p">:</span>
    <span class="n">args</span> <span class="o">=</span> <span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">mu_0</span><span class="p">,</span> <span class="n">r_0</span><span class="p">,</span> <span class="n">s_0</span><span class="p">,</span> <span class="n">a_0</span><span class="p">,</span> <span class="n">b_0</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
    <span class="n">args</span> <span class="o">=</span> <span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">z</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">mu_0</span><span class="p">,</span> <span class="n">r_0</span><span class="p">,</span> <span class="n">s_0</span><span class="p">,</span> <span class="n">a_0</span><span class="p">,</span> <span class="n">b_0</span><span class="p">)</span>

<span class="n">sampler</span> <span class="o">=</span> <span class="n">emcee</span><span class="o">.</span><span class="n">EnsembleSampler</span><span class="p">(</span><span class="n">nchains</span><span class="p">,</span> <span class="n">ndim</span><span class="p">,</span> <span class="n">ln_posterior</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="n">args</span><span class="p">)</span>
<span class="n">rstate</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">get_state</span><span class="p">()</span>
<span class="n">sampler</span><span class="o">.</span><span class="n">run_mcmc</span><span class="p">(</span><span class="n">pos</span><span class="p">,</span> <span class="n">samples_per_chain</span><span class="p">,</span> <span class="n">rstate0</span><span class="o">=</span><span class="n">rstate</span><span class="p">)</span>
<span class="n">samples</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ascontiguousarray</span><span class="p">(</span><span class="n">sampler</span><span class="o">.</span><span class="n">chain</span><span class="p">[:,</span><span class="n">nburn</span><span class="p">:,:])</span>
<span class="n">lnprob</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ascontiguousarray</span><span class="p">(</span><span class="n">sampler</span><span class="o">.</span><span class="n">lnprobability</span><span class="p">[:,</span><span class="n">nburn</span><span class="p">:])</span>
</pre></div>
</div>
<p>where the initial positions are drawn randomly from the support of each covariate prior.</p>
<p>We adopt the hyper-spherical model, and fit the model hyper-parameters through cross-validation as in other examples. This learnt model is then used with the harmonic mean estimator to construct a robust computation of the Bayesian evidence by</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">ev</span> <span class="o">=</span> <span class="n">hm</span><span class="o">.</span><span class="n">Evidence</span><span class="p">(</span><span class="n">chains_test</span><span class="o">.</span><span class="n">nchains</span><span class="p">,</span> <span class="n">model</span><span class="p">)</span>
<span class="n">ev</span><span class="o">.</span><span class="n">add_chains</span><span class="p">(</span><span class="n">chains_test</span><span class="p">)</span>
<span class="n">ln_evidence</span><span class="p">,</span> <span class="n">ln_evidence_std</span> <span class="o">=</span> <span class="n">ev</span><span class="o">.</span><span class="n">compute_ln_evidence</span><span class="p">()</span>
</pre></div>
</div>


           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2021, Jason D. McEwen, Christopher G. R. Wallis, Matthew A. Price.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>